{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Curso de Visión Artificial](imagenes/encabezado.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Características\n",
    "\n",
    "La etapa de extracción de características consiste en calcular un **vector de características** que contenga ciertas medidas o métricas sobre cada uno de los objetos de la imagen. Dichas características son empleadas, más adelante, para entrenar un clasificador que diferencia entre clases de objetos.\n",
    " \n",
    "En este caso utilizaremos el paquete `measure` de `Skimage` cuya documentación se encuentra disponible [aquí](http://scikit-image.org/docs/stable/api/skimage.measure.html).\n",
    " \n",
    "Veamos como extraer características BÁSICAS de los objetos en `Skimage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siempre que usemos matplotlib en Jupyter es necesario poner esta línea antes de cualquier otra\n",
    "%matplotlib inline\n",
    "\n",
    "# Importamos las bibliotecas necesarias y les asignamos un alias\n",
    "import skimage                           # Biblioteca para la manipulación de imágenes\n",
    "import numpy as np                       # Biblioteca para la manipulación de matrices\n",
    "\n",
    "# Importamos algunos paquetes específicos\n",
    "from matplotlib import pyplot as plt     # Biblioteca para crear gráficas y mostrar las imágenes en pantalla\n",
    "\n",
    "from skimage import data                 # Paquete con imágenes de prueba\n",
    "from skimage import io                   # Paquete para lectura/escritura de imágenes\n",
    "from skimage import color                # Paquete con las operaciones de transformaciones entre espacios de color\n",
    "from skimage import exposure             # Paquete con las funciones para calcular y alterar el histograma\n",
    "from skimage import filters              # Paquete que contiene las máscaras y filtros de suavizado y realzado\n",
    "from skimage import util                 # Paquete que contiene las funciones para cambiar el tipo de dato de las imágenes\n",
    "from skimage import morphology           # Para crear el kernel de convolución en los filtros no lienales\n",
    "from skimage import transform            # Esta biblioteca es la que contiene la implementación de Hough\n",
    "from skimage import measure              # Esta biblioteca contiene el método de etiquetado de regiones\n",
    "from skimage import feature              # Esta biblioteca es la que contiene la implementación del canny\n",
    "\n",
    "from scipy import ndimage                # Usamos esta biblioteca para realizar la operación de convolución\n",
    "import skdemo                            # Paquete ESPECIAL ADJUNTO con algunas funciones extra de visualización\n",
    "\n",
    "###########################\n",
    "\n",
    "from scipy.stats import kde              # Esta biblioteca es necesaria para estimar la función de densidad de los datos\n",
    "from sklearn import preprocessing        # Este paquete contiene las funciones de preprocesamiento de datos\n",
    "from sklearn import feature_selection    # Este paquete contiene los métodos de selección de características de sklearn\n",
    "from sklearn import svm                  # Este paquete contiene las funciones de un clasificador SVM\n",
    "from sklearn import model_selection      # Este paquete contiene las funciones de particionamiento de datos y validación cruzada\n",
    "from sklearn import metrics              # Este paquete contiene las funciones para evaluar un clasificador\n",
    "\n",
    "# Con este nos aseguramos que las imágenes en niveles de gris, se vean como tal siempre.\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema: clasificación de flechas\n",
    "\n",
    "La idea con este ejercicio de la práctica es diseñar un clasificador automático de flechas que, por ejemplo, puede ser usado para identificación de señales de tránsito.\n",
    "\n",
    "Para ello se proveen dos imágenes, una que tiene los objetos (flechas) para entrenar un clasificador y otra imagen que contiene los objetos de prueba. Cada una de las imágenes contiene 3 tipos de flechas, como las que se muestra a continuación.\n",
    "\n",
    "![Flechas de Muestra](imagenes/FlechasMuestra.png)\n",
    "\n",
    "Antes que nada, debemos cargar las dos imágenes que contienen nuestros objetos de interés:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las imágenes\n",
    "tr_img = io.imread(\"imagenes/flechas.bmp\")\n",
    "ts_img = io.imread(\"imagenes/flechastest.bmp\")\n",
    "\n",
    "# Como los objetos son negros y el fondo blanco, cambiamos la configuración de la imagen\n",
    "tr_img = (tr_img < 128).astype(\"uint8\")\n",
    "ts_img = (ts_img < 128).astype(\"uint8\")\n",
    "\n",
    "# Mostramos las imágenes\n",
    "skdemo.imshow_all(tr_img, ts_img, titles=[\"Entrenamiento\", \"Prueba\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando las características de los objetos\n",
    "Empecemos extrayendo las características geométricas de una sola flecha. Ponga atención al siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacamos una de las flecas de la imagen\n",
    "f = tr_img[80:170,100:200];\n",
    "plt.imshow(f); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos las características básicas de esa flecha\n",
    "props = measure.regionprops(f, coordinates='rc')\n",
    "#props = measure.regionprops(f)\n",
    "\n",
    "# Visualizamos algunas características de la flecha:\n",
    "print(\"-----------------------------------\\nAlgunas características calculadas:\\n-----------------------------------\")\n",
    "print (\"Area: \",props[0].area)\n",
    "print (\"Centroid: \",props[0].centroid)\n",
    "print (\"Eccentricity: \",props[0].eccentricity)\n",
    "print (\"Diameter: \",props[0].equivalent_diameter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por favor, consulte la documentación de la función <span style=\"background-color:#DDDDDD; color:blue; font-family:Courier new\">measure.regionprops</span> para que lea que otras características extrae esta función.\n",
    "\n",
    "Ahora vemos como extraer las características de todos los objetos en la imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note que las flechas del mismo tipo están agrupadas en la imagen de entrenamiento\n",
    "# Aplicamos el método de etiquetado de componentes conexas para identificar los píxeles que pertenecen a cada flecha\n",
    "f1 = measure.label(tr_img[:, :375]) #Flechas unidireccionales curvas\n",
    "f2 = measure.label(tr_img[:, 375:620]) #Flechas bidireccionales\n",
    "f3 = measure.label(tr_img[:, 620:]) #Flechas unidireccionales rectas\n",
    "\n",
    "# Visualizamos los objetos etiquetados\n",
    "skdemo.imshow_all(f1, f2, f3, cmap=\"jet\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora debemos asignar MANUALMENTE la etiqueta de clase de cada objeto en la imagen. Donde la clase 1 son las flechas unidireccionales curvas, la clase 2 son las flechas bidireccionales y la clase 3 son las flechas unidireccionales rectas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea el vector de etiqueta de cada clase\n",
    "y1 = np.full((f1.max(),1), 1) #Flechas unidireccionales curvas\n",
    "y2 = np.full((f2.max(),1), 2) #Flechas bidireccionales\n",
    "y3 = np.full((f3.max(),1), 3) #Flechas unidireccionales rectas\n",
    "\n",
    "y = np.vstack([y1,y2,y3])\n",
    "y = np.ravel(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a extraer las características de forma de todas las flechas de cada tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por cada grupo de flechas, se extraen las características de cada objeto en la imagen, es decir de cada flecha\n",
    "props_f1 = measure.regionprops(f1, coordinates='rc')\n",
    "props_f2 = measure.regionprops(f2, coordinates='rc')\n",
    "props_f3 = measure.regionprops(f3, coordinates='rc')\n",
    "\n",
    "#props_f1 = measure.regionprops(f1)\n",
    "#props_f2 = measure.regionprops(f2)\n",
    "#props_f3 = measure.regionprops(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLO a modo de ejemplo, mostremos en la imagen el rectángulo envolvente y el centroide de cada flecha en el grupo 1\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(f1, cmap=\"jet\")\n",
    "\n",
    "# Muestre la caja envolvente de cada flecha y el centroide de las flechas tipo 1:\n",
    "for region in props_f1:\n",
    "    x1 = region.bbox[1] #Columna\n",
    "    y1 = region.bbox[0] #Fila\n",
    "    w = region.bbox[3] - region.bbox[1] #Ancho\n",
    "    h = region.bbox[2] - region.bbox[0] #Alto\n",
    "    rc = Rectangle((x1, y1), w, h, linewidth=1, edgecolor='red', fill=False)\n",
    "    ax.add_artist(rc)\n",
    "    \n",
    "    c = Circle((region.centroid[1], region.centroid[0]), radius=5, linewidth=1, edgecolor='yellow', facecolor='yellow')\n",
    "    ax.add_artist(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando las características de forma individual\n",
    "\n",
    "Una vez calculadas las características (en este caso las básicas de forma) procedemos a hacer un análisis de las mismas (lo que hicimos con las mandarinas). Para ello graficamos la distribución de cada característica de manera individual. En este caso mostremos la distribución del área por tipo de flecha.\n",
    "\n",
    "En este caso nos toca agrupar todas las áreas de cada grupo de flechas en un vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el área de todos los objetos en las 3 subimagenes\n",
    "# La siguiente instrucción crea un arreglo [] en el que iterativamente (con el for) se van \n",
    "# agregando las áreas de cada flecha, la cual está en la lista de características props_f*\n",
    "areas_f1 = [r.area for r in props_f1]\n",
    "areas_f2 = [r.area for r in props_f2]\n",
    "areas_f3 = [r.area for r in props_f3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a visualizar los valores del área entre los diferentes tipos de flechas. Esto lo podemos hacer usando histogramas, como se muestra a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para iniciar concatenamos en un vector todas las áreas para obtener el valor máximo de las mismas\n",
    "areas = np.hstack((areas_f1,areas_f2, areas_f3))\n",
    "M = areas.max()\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=[17,5])\n",
    "\n",
    "# Una vez tenemos to]das las áreas en tres arreglos diferentes, creamos los histogramas, usando 100 grupos (o bins)\n",
    "ax[0].hist(areas_f1, bins=100, range=(0, M), color=\"r\")\n",
    "ax[0].set_ylim(0, 15)\n",
    "ax[0].set_title(\"Histograma áreas - Flechas Tipo 1\")\n",
    "\n",
    "ax[1].hist(areas_f2, bins=100, range=(0, M), color=\"g\")\n",
    "ax[1].set_title(\"Histograma áreas - Flechas Tipo 2\")\n",
    "ax[1].set_ylim(0, 15)\n",
    "\n",
    "ax[2].hist(areas_f3, bins=100, range=(0, M), color=\"b\")\n",
    "ax[2].set_ylim(0, 15)\n",
    "ax[2].set_title(\"Histograma áreas - Flechas Tipo 3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma para determinar si la característica es buena o no es visualizar la función de densidad de la variable (estadística), la cual se puede estimar usando KDE (kernel density estimation). A continuación, se muestra un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6])\n",
    "\n",
    "#Estimamos la función densidad del área en cada uno de los tipos de flechas\n",
    "kde1 = kde.gaussian_kde( areas_f1 )\n",
    "kde2 = kde.gaussian_kde( areas_f2 )\n",
    "kde3 = kde.gaussian_kde( areas_f3 )\n",
    "\n",
    "#Graficamos, usando el valor máximo de las áreas de referencia\n",
    "dist_space = np.linspace( 0, M, 100 )\n",
    "plt.plot( dist_space, kde1(dist_space), color = \"r\", label=\"a\")\n",
    "plt.plot( dist_space, kde2(dist_space), color = \"g\")\n",
    "plt.plot( dist_space, kde3(dist_space), color = \"b\")\n",
    "\n",
    "plt.legend(('Flechas Tipo 1', 'Flechas Tipo 2', 'Flechas Tipo 3'), loc='upper right')\n",
    "plt.xlabel('Área')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga presente que esto lo podemos hacer porque tenemos pocos objetos (hay máximo 16 flechas de cada tipo). Sin embargo, cuando hay muchos objetos, por ejemplo, 100 objetos por clase, se debe crear un histograma para la característica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Es el área de las flechas una buena característica?\n",
    "\n",
    "R/="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la excentricidad\n",
    "ecc1 = [r.eccentricity for r in props_f1]\n",
    "ecc2 = [r.eccentricity for r in props_f2]\n",
    "ecc3 = [r.eccentricity for r in props_f3]\n",
    "\n",
    "eccs = np.hstack((ecc1, ecc2, ecc3))\n",
    "M = max(eccs)\n",
    "\n",
    "#Visualizamos la excentricidad de los objetos\n",
    "plt.figure(figsize=[10,8])\n",
    "\n",
    "#Estimamos la función densidad\n",
    "kde1 = kde.gaussian_kde( ecc1 )\n",
    "kde2 = kde.gaussian_kde( ecc2 )\n",
    "kde3 = kde.gaussian_kde( ecc3 )\n",
    "\n",
    "#Graficamos, usando el valor máximo de las áreas de referencia\n",
    "dist_space = np.linspace( 0, M, 100 )\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot( dist_space, kde1(dist_space), color = \"r\")\n",
    "plt.plot( dist_space, kde2(dist_space), color = \"g\")\n",
    "plt.plot( dist_space, kde3(dist_space), color = \"b\")\n",
    "\n",
    "plt.legend(('Flechas Tipo 1', 'Flechas Tipo 2', 'Flechas Tipo 3'), loc='upper right')\n",
    "plt.xlabel('Eccentricity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Es la excentricidad de las flechas una buena característica?\n",
    "\n",
    "R/="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización del espacio de dos características\n",
    "Escoja de a 2 características para graficar la distribución de las clases y encuentre una combinación que muestre \n",
    "una buena separabilidad. En este ejemplo se muestra la distribución para las características del area vs excentricidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,10])\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(areas_f1, ecc1, marker='x', color='r')\n",
    "ax.scatter(areas_f2, ecc2, marker='o', color='g')\n",
    "ax.scatter(areas_f3, ecc3, marker='*', color='b')\n",
    "\n",
    "ax.legend(('Flechas 1', 'Flechas 2', 'Flechas 3'), loc='best')\n",
    "ax.set_xlabel('Área', fontsize=15)\n",
    "ax.set_ylabel('Excentricidad', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Son este par de características adecuadas para clasificar y diferenciar entre las flechas?\n",
    "\n",
    "R/="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Forme parejas de características y encuentre aquellas que permitan separar las flechas. Discuta porque cada pareja seleccionada sirve o no para el propósito de separación.\n",
    "\n",
    "R/="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando la Matriz de Características\n",
    "\n",
    "La función <span style=\"background-color:#DDDDDD; color:blue; font-family:Courier new\">measure.regionprops</span> calcula sólo algunas de las características de forma de los objetos en la imagen. No obstante, cuando se trabaja en problemas de reconocimiento se suelen utilizar diferentes tipos de características a la vez. El ejemplo a continuación, ilustra como calcular diferentes tipos de características, con diferentes bibliotecas para python.\n",
    "\n",
    "El vector de características que vamos contiene:\n",
    "- Características de Forma: área, perímetro, solidez, excentricidad, Centroide_X, Centroide_Y, diametro_equi, longitud_eje_mayor y la longitud_eje_menor y los momentos_hu\n",
    "- Características de Textura: No se pueden calcular porque no hay imagen en niveles de gris\n",
    "- Características de Color: No se pueden calcular porque no hay imagen en niveles de gris\n",
    "\n",
    "Veamos como hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuerde que ya calculamos algunas de estas características\n",
    "# Esas características están en tres variables diferentes: props_f1, props_f2 y  props_f3\n",
    "# Lo primero que hacemos es pegar esas 3 variables en una sola: y_iter\n",
    "\n",
    "from itertools import chain # Solo lo usamos para juntar los tres iterables en uno\n",
    "y_iter = chain(props_f1, props_f2, props_f3)\n",
    "\n",
    "# Solo, para información, creamos un arreglo con los nombres de las características a calcular\n",
    "Xn = np.array([\"Area\",\n",
    "              \"Perimetro\",\n",
    "              \"Solidez\", \n",
    "              \"Excentricidad\", \n",
    "              \"Centroide X\",\n",
    "              \"Centroide Y\",\n",
    "              \"Diametro Equiv\", \n",
    "              \"Eje Mayor\", \n",
    "              \"Eje Menor\", \n",
    "              \"m1\",\n",
    "              \"m2\",\n",
    "              \"m3\",\n",
    "              \"m4\",\n",
    "              \"m5\",\n",
    "              \"m6\",\n",
    "              \"m7\"\n",
    "              ])\n",
    "\n",
    "# Creamos la matriz de datos vacía\n",
    "X = None\n",
    "\n",
    "# Lo que debemos hacer es recorrer cada objeto e ir concatenado las características de estos\n",
    "for obj in y_iter:\n",
    "    X_obj = np.array([\n",
    "                obj.area,\n",
    "                obj.perimeter,\n",
    "                obj.solidity,        \n",
    "                obj.eccentricity,\n",
    "                obj.centroid[0],\n",
    "                obj.centroid[1],\n",
    "                obj.equivalent_diameter,\n",
    "                obj.major_axis_length,\n",
    "                obj.minor_axis_length,\n",
    "                obj.moments_hu[0],\n",
    "                obj.moments_hu[1],\n",
    "                obj.moments_hu[2],\n",
    "                obj.moments_hu[3],\n",
    "                obj.moments_hu[4],\n",
    "                obj.moments_hu[5],\n",
    "                obj.moments_hu[6]\n",
    "    ])\n",
    "    \n",
    "    #Agregamos las características del objeto a la matriz X\n",
    "    if X is None:\n",
    "        X = X_obj.copy()\n",
    "    else:\n",
    "        X = np.vstack((X, X_obj))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de los datos\n",
    "\n",
    "Lo primero que debemos hacer es normalizar (o escalar) las características. En este caso usamos una \"normalización\" MaxMin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se aplica la función para escalar los datos\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scl = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpiar las Características Irrelevantes\n",
    "\n",
    "Ahora demos eliminar aquellas características que pueden considerarse completamente irrelevantes, es decir se deben eliminar todas las características cuya varianza no cumple con umbral determinado. Esto nos permite, por ejemplo, eliminar aquellas características cuyo valor es el mismo para todos los objetos.\n",
    "\n",
    "La función feature_selection.VarianceThreshold de sklearn nos permite hacer esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el selector de características para eliminar las irrelevantes\n",
    "selector = feature_selection.VarianceThreshold()\n",
    "\n",
    "# Creamos la nueva matriz de características\n",
    "X_new1 = selector.fit_transform(X_scl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestre en pantalla el tamaño de ambas matrices. Nota alguna diferencia? Qué significa aquella diferencia?\n",
    "\n",
    "R/="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de características por análisis individual\n",
    "Ahora hagamos un análisis individual de las características basados en una métrica que se llama Información Mutua, la cual mide la dependencia entre cada característica y la etiqueta de clase de los objetos. Un valor de 0 indica que la característica es irrelevante, entre más alto el valor, mayor la relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuerde que las etiquetas de clase de las flechas las tenemos en un arreglo llamado y\n",
    "print (\"Etiquetas de los datos:\\n\", y)\n",
    "\n",
    "# Calculamos el criterio de información mutua\n",
    "mi = feature_selection.mutual_info_classif(X_scl, y)\n",
    "\n",
    "# Visualizamos el valor de la métrica usando un gráfico de puntos\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(mi, 'o-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Con base en este gráfico qué características escogería usted?\n",
    "\n",
    "R/="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora empleemos la información mutua para hacer la selección\n",
    "transformer = feature_selection.GenericUnivariateSelect(feature_selection.mutual_info_classif, 'k_best', param=5)\n",
    "\n",
    "#Creamos la nueva matriz de características\n",
    "X_new1 = transformer.fit_transform(X_scl, y)\n",
    "\n",
    "#Obtenemos los índices de las características seleccionadas\n",
    "idx = transformer.get_support(indices=True)\n",
    "\n",
    "#Filtramos los nombres de las nuevas características\n",
    "Xn_new1 = Xn[idx]\n",
    "\n",
    "#¿Qué características nos quedan?\n",
    "print(\"Características seleccionadas por análisis individual:\", Xn_new1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección recursiva de características \n",
    "\n",
    "Uno de los métodos de selección de características en esta categoría es el método de selección hacia atrás. Este método asigna un peso a cada característica (de acuerdo a alguna métrica como la precisión de clasificación) y va descartando, paso a paso, la característica menos importante. Este procedimiento se repite de forma recursiva hasta que finalmente se alcanza el número deseado de características para seleccionar.\n",
    "\n",
    "Veamos como hacer esto en sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este caso, la métrica de selección es la precisión de clasificación usando una SVM lineal\n",
    "\n",
    "# Creamos el clasificador\n",
    "svc = svm.SVC(kernel=\"linear\", C=1)\n",
    "\n",
    "# Definimos el método de selección indicando que vamos a seleccionar 5 características\n",
    "rfe = feature_selection.RFE(estimator=svc, n_features_to_select=5, step=1)\n",
    "\n",
    "#Creamos la nueva matriz de características\n",
    "X_new2 = rfe.fit_transform(X_scl, y)\n",
    "\n",
    "# Visualizamos como quedaron organizadas las características.\n",
    "# Aquellas con valor 1 son las seleccionadas\n",
    "print (\"Ranking de Caracteríticas: \", rfe.ranking_)\n",
    "\n",
    "# Características seleccionadas\n",
    "idx = rfe.get_support(indices=True)\n",
    "\n",
    "#Filtramos los nombres de las nuevas características\n",
    "Xn_new2 = Xn[idx]\n",
    "\n",
    "#¿Qué características nos quedan?\n",
    "print(\"Características seleccionadas por selección hacia atrás:\", Xn_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección automática del número de características\n",
    "\n",
    "Uno de los parámetros que se debe definir en el método anterior es el número de características a seleccionar. No obstante, el siguiente método (basado en selección hacia atrás) determina automáticamente (usando una validación cruzada) cuál es el número de características más adecuado para clasificar los datos.\n",
    "\n",
    "Veamos cómo hacerlo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero definimos el clasificador a usar en la selección automática\n",
    "svc = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "# En este caso usamos la precisión del clasificador como métrica de selección\n",
    "# Así que aquí configuramos el selector automático\n",
    "rfecv = feature_selection.RFECV(estimator=svc, step=1, \n",
    "                                cv=model_selection.StratifiedKFold(2), \n",
    "                                scoring='accuracy')\n",
    "\n",
    "# Aplicamos el método de selección\n",
    "X_new3 = rfecv.fit_transform(X_scl, y)\n",
    "\n",
    "#Visualizamos el número óptimo de características a usar\n",
    "print(\"Número óptimo de características: %d\" % rfecv.n_features_)\n",
    "\n",
    "# Veamos el gráfico de rendimiento del clasificador VS el número de características\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel(\"Numbero of características seleccionadas\")\n",
    "plt.ylabel(\"Precisión en la Validación Cruzada\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si usted examina el gráfico anterior, se dará cuenta que con 2 características es suficiente para clasificar correctamente todas las flechas, sin embargo, el método dice que se deben usar las 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando las características para clasificar\n",
    "\n",
    "El último paso consiste en entrenar un clasificador usando el conjunto de características que se seleccionaron. Entrenemos un clasificador fácil: una SVM con un kernel lineal (luego vemos en detalle que es esto).\n",
    "\n",
    "Veamos el código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Como solo contamos con un conjunto de datos etiquetado es necesario que lo dividamos.\n",
    "# Normalmente, se suele usar el 66.6% para entrenar y el 33.3% para probar el clasificador.\n",
    "# Esta partición la hacemos con StratifiedKFold, el cual además nos permite entrenar con 2/3 y evaluar con 1/3, 3 veces\n",
    "# A esto se le llama Validación Cruzada (CrossValidation con k=3) en Aprendizaje de Máquina.\n",
    "cv = model_selection.StratifiedKFold(n_splits=3)\n",
    "\n",
    "# Ahora definimos el clasificador a utilizar, en este caso una SVM con un kernel lineal\n",
    "classifier = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "\n",
    "#scores = model_selection.cross_val_score(classifier, X, y, cv=cv)\n",
    "#print(scores) \n",
    "\n",
    "#scores = model_selection.cross_validate(classifier, X, y, cv=cv)\n",
    "#print(scores) \n",
    "\n",
    "i = 1\n",
    "suma = 0\n",
    "# Cómo vamos a entrenar y validar 3 veces debemos hacerlo en un ciclo\n",
    "for train_idx, test_idx in cv.split(X_new1, y):\n",
    "    \n",
    "    #Partimos el conjunto de datos\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "   \n",
    "    # Entrenamos el clasificador\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluamos el clasificador con los datos de prueba (test)\n",
    "    y_predicted = classifier.predict(X_test)\n",
    "    acc = metrics.accuracy_score(y_test, y_predicted)\n",
    "    suma += acc;\n",
    "    print (\"Precisión del clasificador \", i, \": \", acc)\n",
    "    \n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.title('Matriz del Classificador '+str(i))\n",
    "    \n",
    "    # Creamos la matriz de confusión con las etiquetas reales y las predichas\n",
    "    mat = metrics.confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "    # Mostramos la matriz de confusión como un mapa de calor\n",
    "    sns.heatmap(mat, square=True, annot=True, cbar=True, cmap=\"Blues\")\n",
    "\n",
    "    # Agregamos los nombres de los ejes\n",
    "    plt.xlabel('Valor del Clasificador')\n",
    "    plt.ylabel('Valor Real');\n",
    "\n",
    "    \n",
    "    i += 1\n",
    "    #print (metrics.classification_report(y_test, y_predicted))\n",
    "\n",
    "print('La precisión promedio obtenida es de: ', (suma/3))\n",
    "    \n",
    "# Listo! Tenemos un clasificador entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las matrices de confusión nos permiten evaluar que tan buenos fueron los clasificadores entrenados con el conjunto de datos original partido en tres partes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entregables de la práctica\n",
    "\n",
    "Tenga en cuenta que se evalúa calidad del entregable, las explicaciones dadas, la redacción, la ortografía, así como la calidad del código (si es entendible, limpio, ordenado, bien comentado y no ha solo sido copiado y pegado de lo realizado por el profe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entregable 1: Clasificación sin selección de características\n",
    "\n",
    "Para el desarrollo de esta práctica se entregan tres conjuntos de datos:\n",
    "\n",
    "- Tortillas: que es un conjunto con tres clases (que hacen referencia a 3 calidades de tortillas mexicanas. El conjunto de datos tiene 300 muestras en total para las que se han extraído 1643 características.\n",
    "\n",
    "- Rostros, es un conjunto de datos con dos clases (cara/no-cara). Este conjunto tiene 264 muestras en total con 1589 características.\n",
    "\n",
    "- Género: este conjunto tiene 2 clases (female/male), con un total de 610 muestras, cada una con 1589 características calculadas\n",
    "\n",
    "A Desarrollar para cada conjunto de datos:\n",
    "1. Cargue los archivos de los conjuntos de datos adjuntos (los datos ya están normalizados)\n",
    "2. Divida el conjunto de datos en 2 subconjuntos: un conjunto con el 80% de las muestras de cada clase para el  entrenamiento (training) y otro con el 20% restante como conjunto de pruebas (testing). Esto lo puede hacer manualmente o puede utilizar la función <span style=\"background-color:#DDDDDD; color:blue; font-family:Courier new\">model_selection.train_test_split</span> para hacer la partición. Es necesario hacer esto y no copiar y pegar lo implementado en la práctica ya que en este caso sólo se entrenará un clasificador y usted NO hará Validación Cruzada.\n",
    "3. Entrene un clasificador (puede ser la SVM lineal usada en esta práctica) o puede usar un clasificador como el clasificador de vecinos más cercanos, kNN (<span style=\"background-color:#DDDDDD; color:blue; font-family:Courier new\">neighbors.KNeighborsClassifier</span> de `sklearn`). El clasificador debe ser entrenado con los datos de entrenamiento de la partición del punto anterior.\n",
    "4. Use el conjunto de prueba para evaluar el clasificador: muestre la precisión del mismo y la matriz de confusión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí el código de este entregable\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "#Punto 1: Conjunto de datos de las Tortillas\n",
    "mat = scipy.io.loadmat('datos/set04-tortillas.mat')\n",
    "\n",
    "y = mat['d'] # Etiquetas de clase de los objetos\n",
    "X = mat['f'] # Matriz de datos: 300 objetos (filas) x 1643 características (columnas)\n",
    "Xn = mat['fn'] # Nombres de las características\n",
    "\n",
    "# Aquí ya puede continuar usted ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entregable 2: Clasificación con selección de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Desarrollar para cada conjunto de datos de entrenamiento:\n",
    "1. Elimine las características irrelevantes y llame al conjunto de datos resultante X_train_1\n",
    "2. Aplique el método de selección hacia atrás (en la sección selección recursiva de características) y cree un nuevo conjunto de datos con 100 características (llame a este conjunto X_train_2).\n",
    "3. Sobre el conjunto resultante en el punto anterior, aplique el algoritmo de selección automática hacia atrás (en la sección selección automática del número de características). Cuántas características son relevantes para el conjunto de datos?\n",
    "4. A partir de la selección anterior cree un nuevo conjunto de datos y llámelo (X_train_3)\n",
    "5. Haga un análisis individual de las características del conjunto de datos resultante del punto anterior y seleccione de él las 10 menores características (llame a este nuevo conjunto de datos X_train_4). Cuáles son los nombres de las características seleccionas en este último paso?\n",
    "5. Con base en la selección de los pasos 1, 2, 4 y 5, genere los conjuntos de datos de prueba X_test_1, X_test_2, X_test_3 y X_test_4.\n",
    "6. Por cada conjunto de datos X_train_*, entrene un clasificador (Del mismo tipo usado en el entregable 1) y evalúe el mismo con el conjunto de datos de prueba correspondiente. muestre la precisión del mismo y la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí el código de este entregable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entregable 3: Análisis de los resultados obtenidos\n",
    "\n",
    "1. Grafique las 2 mejores características obtenidas en la última selección usando un scatter. Qué tan buenas son para cada conjunto de datos?\n",
    "2. Con base en las matrices de confusión y la precisión de los clasificadores, qué conclusiones puede sacar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R/= Aquí su análisis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
